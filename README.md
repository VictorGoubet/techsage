<p align="center">
  <img src="logo.png" alt="TechSage Logo" width="200">
</p>

<h1 align="center">TechSage ü§ñ</h1>

<p align="center">
  TechSage is a multi-agent LLM platform delivering daily insights on technology, programming, cloud architecture, and more. Utilize OpenAI's LLMs or local models via Ollama, powered by CrewAI's multi-agent system, to stay ahead in the tech world.
</p>

<p align="center">
  <a href="#prerequisites">Prerequisites</a> ‚Ä¢
  <a href="#installation">Installation</a> ‚Ä¢
  <a href="#configure">Configure</a> ‚Ä¢
  <a href="#launch">Launch</a> ‚Ä¢
  <a href="#docker">Docker</a>
</p>

<br>

## Prerequisites üí°

- Python >= 3.10, <= 3.13
- `ollama` (if using a local model) [install here](https://ollama.com/download/)
- May need to install the c++ build tool if you don't already have it

## Installation üõ†Ô∏è

To install TechSage, run:

```bash
pip install https://github.com/VictorGoubet/techsage/archive/refs/tags/v1.tar.gz
```

*Replace `v1.0.0` with the release you want to use.*

## Configure [optional] ‚öôÔ∏è

Execute this command only if you want to use the shell interface with specific configuration. For the Streamlit interface, you can configure everything directly within it.

```bash
configure-sage
```

### Configuration Options:

- `--model <your-model-name>`: Name of the model to use (default: `llama3:8b`).
- `--model_url <your-model-url>`: API URL of the model to use (default: `http://localhost:11434/v1`).
- `--verbose <1 or 0>`: Verbose level during configuration (default: 0).
- `--local <True or False>`: Use a local model with Ollama or an OpenAI API model (default: True).
- `--openai_api_key <key>`: Your OpenAI API key (required if local mode is disabled or using crew memory).
- `--google_search_api_key <key>`: Delpha Google Search API key. If empty, a local Google search will be performed. Modify `api_google_search` method in `tools.py` to use another API. A DuckDuckGo tool is also available.

## Launch üöÄ

After setting up, launch the script with admin rights. If no configuration is provided, the default configuration will be used:

```sh
launch-sage
```

### Launch Options:

- `--streamlit <true or false>`: If `true`, the Streamlit interface will be used; otherwise, a shell interface will appear.

<br>

## Docker üêã

Lazy to setup everything ? Just use the dedicated docker image and go to [http://localhost:8501](http://localhost:8501)

### CPU only

```bash
docker run -d -v ollama:/root/.ollama -p 8501:8501 victorgoubet/techsage:latest
```

### Nvidia GPU (Not working for now)

First install the [NVIDIA Container Toolkit‚Å†](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installation).
For windows you may need to check [Nvidia Cuda on WSL](https://learn.microsoft.com/fr-fr/windows/ai/directml/gpu-cuda-in-wsl) 

```bash
docker run -d --gpus=all -v ollama:/root/.ollama -p 8501:8501 victorgoubet/techsage:latest
```

---
